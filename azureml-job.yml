$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json
type: pipeline
display_name: BERT Sentiment Training Pipeline
experiment_name: imdb-sentiment-bert

inputs:
  dataset_path: 
    type: uri_folder
    path: azureml://datastores/workspaceblobstore/paths/imdb-data/ # Path to your dataset in Blob Storage

settings:
 default_compute: azureml:serverless

jobs:
  preprocess:
    type: command
    code: ./src  # Folder with your scripts
    command: >-
      python preprocess.py 
      --input_data ${{inputs.dataset_path}} 
      --output_data ${{outputs.preprocessed_data}}
    environment: azureml:bert-cpu-env@latest  # Custom env with Transformers
    inputs:
      dataset_path: ${{parent.inputs.dataset_path}}
    outputs:
      preprocessed_data:
        type: uri_folder

  train:
    type: command
    code: ./src
    command: >-
      python train_bert.py 
      --input_data ${{inputs.preprocessed_data}} 
      --model_output ${{outputs.model_output}}
    environment: azureml:bert-gpu-env@latest  # GPU env with Transformers
    inputs:
      preprocessed_data: ${{parent.jobs.preprocess.outputs.preprocessed_data}}
    outputs:
      model_output:
        type: mlflow_model

  register:
    type: command
    code: ./src
    command: >-
      python register_model.py 
      --model_path ${{inputs.model_output}} 
      --model_name bert-sentiment-model
    environment: azureml:bert-cpu-env@latest
    inputs:
      model_output: ${{parent.jobs.train.outputs.model_output}}
